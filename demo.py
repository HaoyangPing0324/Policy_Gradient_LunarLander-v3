"""
@Author  : å¹³æ˜Šé˜³
@Email   : pinghaoyang0324@163.com
@Time    : 2025/12/23
@Desc    : LunarLander-v3 æ¨¡å‹å¯è§†åŒ–æ¼”ç¤ºè„šæœ¬ï¼ˆå®æ—¶æ¸²æŸ“ç€é™†è¿‡ç¨‹ï¼‰
@License : MIT License (MIT)
@Version : 1.0
"""

import warnings
warnings.filterwarnings("ignore", category=UserWarning, module="pygame.pkgdata")
import torch
import gymnasium as gym
import time
import numpy as np
from policy_network import PolicyNetwork  # å¯¼å…¥ä½ çš„ç­–ç•¥ç½‘ç»œ

def load_trained_model(model_path="./lunar_lander_policy_gradient.pth"):
    """åŠ è½½è®­ç»ƒå¥½çš„æ¨¡å‹ï¼ˆä¸è®­ç»ƒæ—¶çš„ç½‘ç»œç»“æ„ä¸¥æ ¼ä¸€è‡´ï¼‰"""
    # å›ºå®šå‚æ•°ï¼ˆéœ€ä¸è®­ç»ƒæ—¶å®Œå…¨åŒ¹é…ï¼‰
    OBS_DIM = 8
    ACTION_DIM = 4
    HIDDEN_LAYERS = [256, 128]
    ACTIVATION = 'relu'

    # è®¾å¤‡é…ç½®
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    print(f"æ¼”ç¤ºè®¾å¤‡ï¼š{device}")

    # åˆ›å»ºç½‘ç»œå¹¶åŠ è½½æƒé‡
    policy_net = PolicyNetwork(
        obs_dim=OBS_DIM,
        action_dim=ACTION_DIM,
        hidden_layers=HIDDEN_LAYERS,
        activation=ACTIVATION,
        device=device
    )

    try:
        state_dict = torch.load(model_path, map_location=device)
        policy_net.load_state_dict(state_dict)
        policy_net.eval()  # åˆ‡æ¢åˆ°è¯„ä¼°æ¨¡å¼
        print(f"âœ… æ¨¡å‹åŠ è½½æˆåŠŸï¼š{model_path}")
        return policy_net
    except Exception as e:
        raise ValueError(f"âŒ æ¨¡å‹åŠ è½½å¤±è´¥ï¼š{e}\nè¯·ç¡®è®¤æ¨¡å‹æ–‡ä»¶å­˜åœ¨ä¸”ç½‘ç»œç»“æ„åŒ¹é…ï¼")

def demo_lander(policy_net, num_demos=3, render_delay=0.01):
    """å¯è§†åŒ–æ¼”ç¤ºé£èˆ¹ç€é™†"""
    # åˆ›å»ºå¸¦æ¸²æŸ“çš„ç¯å¢ƒï¼ˆhumanæ¨¡å¼æ˜¾ç¤ºçª—å£ï¼‰
    env = gym.make("LunarLander-v3", render_mode="human")
    print(f"\nğŸ® å¼€å§‹å¯è§†åŒ–æ¼”ç¤ºï¼ˆå…±{num_demos}å›åˆï¼‰...")
    print("æç¤ºï¼šæ¼”ç¤ºçª—å£å¯æ‰‹åŠ¨å…³é—­ï¼ŒæŒ‰Ctrl+Cç»ˆæ­¢ç¨‹åº")

    # ç¦ç”¨æ¢¯åº¦è®¡ç®—ï¼ˆæå‡æ¼”ç¤ºé€Ÿåº¦ï¼‰
    with torch.no_grad():
        for demo_round in range(num_demos):
            print(f"\n===== æ¼”ç¤ºå›åˆ {demo_round + 1} =====")
            state, _ = env.reset()
            done = False
            total_reward = 0
            step = 0

            while not done:
                # é€‰æ‹©æœ€ä¼˜åŠ¨ä½œï¼ˆæ— éšæœºæ¢ç´¢ï¼Œä½“ç°æ¨¡å‹çœŸå®èƒ½åŠ›ï¼‰
                action = policy_net.get_best_action(state)
                # æ‰§è¡ŒåŠ¨ä½œ
                next_state, reward, terminated, truncated, _ = env.step(action)
                done = terminated or truncated

                # ç´¯è®¡å¥–åŠ±+è®¡æ•°
                total_reward += reward
                step += 1

                # æ§åˆ¶æ¼”ç¤ºé€Ÿåº¦ï¼ˆé¿å…ç”»é¢è¿‡å¿«ï¼‰
                time.sleep(render_delay)

                # æ›´æ–°çŠ¶æ€
                state = next_state

                # æ‰“å°æ¯æ­¥ä¿¡æ¯ï¼ˆå¯é€‰ï¼‰
                if step % 50 == 0:
                    print(f"  æ­¥æ•° {step} | å½“å‰å¾—åˆ†ï¼š{total_reward:.2f}")

            # å›åˆç»“æŸç»Ÿè®¡
            land_status = "æˆåŠŸç€é™†" if total_reward > 100 else "å æ¯/æœªè¾¾æ ‡"
            print(f"æ¼”ç¤ºå›åˆ {demo_round + 1} ç»“æŸ | æ€»æ­¥æ•°ï¼š{step} | æœ€ç»ˆå¾—åˆ†ï¼š{total_reward:.2f} | çŠ¶æ€ï¼š{land_status}")

    # å…³é—­ç¯å¢ƒ
    env.close()
    print("\nğŸ‰ æ‰€æœ‰æ¼”ç¤ºå›åˆç»“æŸï¼")

if __name__ == "__main__":
    # é…ç½®å‚æ•°
    MODEL_PATH = "./lunar_lander_policy_gradient.pth"  # è®­ç»ƒå¥½çš„æ¨¡å‹è·¯å¾„
    NUM_DEMOS = 3  # æ¼”ç¤ºå›åˆæ•°ï¼ˆå»ºè®®1-5ï¼‰
    RENDER_DELAY = 0.01  # ç”»é¢å»¶è¿Ÿï¼ˆè¶Šå°è¶Šå¿«ï¼Œ0.01ä¸ºæµç•…é€Ÿåº¦ï¼‰

    # æ‰§è¡Œæ¼”ç¤ºæµç¨‹
    try:
        # 1. åŠ è½½æ¨¡å‹
        policy_net = load_trained_model(MODEL_PATH)
        # 2. å¯è§†åŒ–æ¼”ç¤º
        demo_lander(policy_net, num_demos=NUM_DEMOS, render_delay=RENDER_DELAY)
    except KeyboardInterrupt:
        print("\nâš ï¸ æ¼”ç¤ºè¢«æ‰‹åŠ¨ç»ˆæ­¢")
    except Exception as e:
        print(f"\nâŒ æ¼”ç¤ºå‡ºé”™ï¼š{e}")